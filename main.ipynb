{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from nadaray_watson_ce import nadaraya_watson_ece, dirichlet_calibration_error\n",
    "from projected_ce import top_calibration_error, class_wise_calibration_error, projected_calibration_error\n",
    "from utils import median_heuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generative_model(key, alpha, beta, pi, n_samples):\n",
    "    \"\"\"\n",
    "    Simulates the generative model described in the text.\n",
    "\n",
    "    Parameters:\n",
    "    - key: JAX random key.\n",
    "    - alpha: Dirichlet concentration parameters (m-dimensional).\n",
    "    - beta: Category probabilities for Y|Z=0 (m-dimensional).\n",
    "    - pi: Bernoulli parameter for Z.\n",
    "    - n_samples: Number of samples to generate.\n",
    "\n",
    "    Returns:\n",
    "    - g_X: Predictions g(X), sampled from Dir(alpha).\n",
    "    - Z: Latent variable Z, sampled from Ber(pi).\n",
    "    - Y: Labels Y, sampled conditionally on Z and g(X).\n",
    "    \"\"\"\n",
    "    keys = jax.random.split(key, 3)\n",
    "\n",
    "    # Sample g(X) ~ Dir(alpha)\n",
    "    g_X = jax.random.dirichlet(keys[0], alpha, shape=(n_samples,))\n",
    "\n",
    "    # Sample Z ~ Ber(pi)\n",
    "    Z = jax.random.bernoulli(keys[1], p=pi, shape=(n_samples,)).astype(jnp.float32)\n",
    "\n",
    "    # Compute the combined distribution for Y\n",
    "    dist = (1 - Z[:, None]) * g_X + Z[:, None] * beta[None, :]\n",
    "\n",
    "    # Sample Y from the categorical distribution using dist\n",
    "    Y = jax.random.categorical(keys[2], logits=jnp.log(dist), axis=1)\n",
    "\n",
    "    return g_X, Z, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2777148048.py, line 39)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 39\u001b[0;36m\u001b[0m\n\u001b[0;31m    error =\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "params = {\n",
    "        \"dim\":10 , \n",
    "        \"alpha\":1*jnp.ones(10,), \n",
    "        \"beta\":1*jnp.ones(10,),\n",
    "        \"pi_m1\":0.0 , \n",
    "        \"pi_m2\":0.2 , \n",
    "        \"pi_m3\":0.6, \n",
    "        \"kernelized\":False, \n",
    "        \"num_bins\":20, \n",
    "        \"equal_size\":False , \n",
    "        \"num_proj\"\n",
    "    }\n",
    "\n",
    "calibration_methods = {\n",
    "        \"top_class\": lambda probs, labels: top_calibration_error(probs, labels, num_bins=params['num_bins'], equal_size=params['equal_size']),\n",
    "        \"random_projected\": lambda key, probs, labels: projected_calibration_error(key, probs, labels, num_bins=params['num_bins'] ,  equal_size=params['equal_size']))\n",
    "    }\n",
    "\n",
    "jitted_calibration_methods = {k:jax.jit(calibration_methods[k]) for k in calibration_methods.keys()}\n",
    "\n",
    "# Main experimental function\n",
    "def run_experiments(key,params:dict, calibration_methods:dict, num_runs=100, num_samples=1000):\n",
    "    \n",
    "    \n",
    "    methods_name = list(calibration_methods.keys())\n",
    "    all_results = {\"M1\": {m:[] for m in methods_name},\n",
    "                   \"M2\": {m:[] for m in methods_name},\n",
    "                   \"M3\": {m:[] for m in methods_name}}\n",
    "    \n",
    "    models = {\n",
    "        \"M1\": lambda key: generative_model(key,params['alpha'], params[\"beta\"], params[\"pi_m1\"], num_samples),\n",
    "        \"M2\": lambda key: generative_model(key,params['alpha'], params[\"beta\"], params[\"pi_m2\"], num_samples),\n",
    "        \"M3\": lambda key: generative_model(key,params['alpha'], params[\"beta\"], params[\"pi_m3\"], num_samples),\n",
    "    }\n",
    "    \n",
    "    for run in range(num_runs):\n",
    "        for model_name, model_fn in models.items():\n",
    "            \n",
    "            if \"random\" in model_name:\n",
    "                key, _ = jax.random.split(key,2)\n",
    "                error = \n",
    "            probs, labels = model_fn()\n",
    "            errors = model_fn()\n",
    "            all_results[model_name].append(errors)\n",
    "\n",
    "\n",
    "# Load or run experiments\n",
    "def load_or_run_experiments():\n",
    "    if os.path.exists(\"calibration_experiment_results.pkl\"):\n",
    "        with open(\"calibration_experiment_results.pkl\", \"rb\") as f:\n",
    "            all_results = pickle.load(f)\n",
    "    else:\n",
    "        all_results = run_experiments()\n",
    "    return all_results\n",
    "\n",
    "# Plot results\n",
    "def plot_results(all_results):\n",
    "    metrics = list(next(iter(all_results.values()))[0].keys())\n",
    "    num_models = len(all_results.keys())\n",
    "    \n",
    "    fig, axes = plt.subplots(len(metrics), num_models, figsize=(12, 8), sharex=False, sharey=False)\n",
    "    fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "    for i, metric in enumerate(metrics):\n",
    "        for j, model in enumerate(all_results.keys()):\n",
    "            ax = axes[i, j]\n",
    "            data = [res[metric] for res in all_results[model]]\n",
    "\n",
    "            # Plot histogram\n",
    "            ax.hist(data, bins=30, alpha=0.7, color='teal', edgecolor='black', density=False)\n",
    "\n",
    "            # Add vertical lines for mean (orange) and dashed blue for zero\n",
    "            ax.axvline(x=np.mean(data), color='orange', linewidth=1.5, label='Mean')\n",
    "            ax.axvline(x=0, color='blue', linestyle='--', linewidth=1.2)\n",
    "\n",
    "            # Set labels and titles\n",
    "            if i == 0:\n",
    "                ax.set_title(f\"{model}\", fontsize=12)\n",
    "            if j == 0:\n",
    "                ax.set_ylabel(f\"{metric}\", fontsize=12)\n",
    "            if i == len(metrics) - 1:\n",
    "                ax.set_xlabel(\"Calibration Error Estimate\", fontsize=10)\n",
    "\n",
    "    # Add legend to one subplot\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc=\"upper right\", fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Execute\n",
    "all_results = load_or_run_experiments()\n",
    "plot_results(all_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
